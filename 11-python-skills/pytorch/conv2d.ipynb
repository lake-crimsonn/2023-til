{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv2D - pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### torch.nn.Conv2d\n",
    "- ```\n",
    "    torch.nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size,\n",
    "        stride=1,\n",
    "        padding=0,\n",
    "        dilation=1,\n",
    "        groups=1,\n",
    "        bias=Truem\n",
    "        padding_mode='zeros'\n",
    "    )\n",
    "    ```\n",
    "#### 파라미터 계산\n",
    "- 커널사이즈^2 * 채널 * 파라미터 + 바이어스(파라미터 수)\n",
    "- `self.conv1 = nn.Conv2d(1, 6, 5)`\n",
    "- 채널:1, 파라미터:6, 커널사이즈:5\n",
    "- 25 * 1 * 6 + 6 = 156\n",
    "\n",
    "#### 출력 사이즈 계산\n",
    "- (입력사이즈 + 2*패딩사이즈) - 커널사이즈 / 스트라이드 + 1\n",
    "- `Input size: (7,7), Kernel size: (3,3) padding: (0,0), stride: (1,1)`\n",
    "- ( 7 + 2 * 0 ) - 3 / 1 + 1 = 5 -> 출력사이즈: (5,5)\n",
    "- 패딩이 1이면 입력사이즈와 출력사이즈는 같다.\n",
    "- `padding: (1,1)` -> 출력사이즈: (7,7)\n",
    "- **기억해야 될 점은 패딩이 1이 아닌 이상 출력사이즈는 계속 줄어든다.**\n",
    "\n",
    "#### 맥스풀링\n",
    "- `torch.nn.functional.max_pool2d(2,2)`\n",
    "- (커널사이즈, 스트라이드)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 입력 이미지 채널 1개, 출력 채널 6개, 5x5의 정사각 컨볼루션 행렬\n",
    "        # 컨볼루션 커널 정의\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # 아핀(affine) 연산: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)  # 5*5은 이미지 차원에 해당\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (2, 2) 크기 윈도우에 대해 맥스 풀링(max pooling)\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # 크기가 제곱수라면, 하나의 숫자만을 특정(specify)\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = torch.flatten(x, 1) # 배치 차원을 제외한 모든 차원을 하나로 평탄화(flatten)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- summary()를 이용하기 위해서는 torchsummary 모듈이 설치되어 있어야 한다.\n",
    "- `RuntimeError: input type, weight type`\n",
    "- 모델을 설정했으면 디바이스와 연결해주어야 한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x2704 and 400x120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorchsummary\u001b[39;00m\n\u001b[0;32m      2\u001b[0m net\u001b[39m.\u001b[39mto(\u001b[39m'\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m torchsummary\u001b[39m.\u001b[39;49msummary(net,(\u001b[39m1\u001b[39;49m,\u001b[39m64\u001b[39;49m,\u001b[39m64\u001b[39;49m))\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\torchsummary\\torchsummary.py:72\u001b[0m, in \u001b[0;36msummary\u001b[1;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[0;32m     68\u001b[0m model\u001b[39m.\u001b[39mapply(register_hook)\n\u001b[0;32m     70\u001b[0m \u001b[39m# make a forward pass\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39m# print(x.shape)\u001b[39;00m\n\u001b[1;32m---> 72\u001b[0m model(\u001b[39m*\u001b[39;49mx)\n\u001b[0;32m     74\u001b[0m \u001b[39m# remove these hooks\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[39mfor\u001b[39;00m h \u001b[39min\u001b[39;00m hooks:\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[7], line 25\u001b[0m, in \u001b[0;36mNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmax_pool2d(F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv2(x)), \u001b[39m2\u001b[39m)\n\u001b[0;32m     24\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mflatten(x, \u001b[39m1\u001b[39m) \u001b[39m# 배치 차원을 제외한 모든 차원을 하나로 평탄화(flatten)\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc1(x))\n\u001b[0;32m     26\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc2(x))\n\u001b[0;32m     27\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc3(x)\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\module.py:1538\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1535\u001b[0m     bw_hook \u001b[39m=\u001b[39m hooks\u001b[39m.\u001b[39mBackwardHook(\u001b[39mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[0;32m   1536\u001b[0m     args \u001b[39m=\u001b[39m bw_hook\u001b[39m.\u001b[39msetup_input_hook(args)\n\u001b[1;32m-> 1538\u001b[0m result \u001b[39m=\u001b[39m forward_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m   1539\u001b[0m \u001b[39mif\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks:\n\u001b[0;32m   1540\u001b[0m     \u001b[39mfor\u001b[39;00m hook_id, hook \u001b[39min\u001b[39;00m (\n\u001b[0;32m   1541\u001b[0m         \u001b[39m*\u001b[39m_global_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1542\u001b[0m         \u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks\u001b[39m.\u001b[39mitems(),\n\u001b[0;32m   1543\u001b[0m     ):\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x2704 and 400x120)"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "net.to('cuda')\n",
    "torchsummary.summary(net,(1,64,64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RuntimeError: mat1 and mat2 shapes cannot be multiplied (2x2704 and 400x120)`\n",
    "- self.fc1 = nn.Linear(16 * 5 * 5, 120) 이 부분 때문에 오류가 난다.\n",
    "- (64,64)는 forward를 진행하면서 사이즈가 (5,5)가 되지 않기 때문이다.\n",
    "- 64 forward process\n",
    "  - conv1: 60\n",
    "  - max: 30\n",
    "  - conv2: 26\n",
    "  - max: 13\n",
    "  - fc1: 16 * 13 * 13\n",
    "- conv1에서 출력사이즈가 60인 이유는 패딩이 디폴트로 0으로 설정되어서, 입력사이즈가 계속 줄어들기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
      "            Linear-3                  [-1, 120]          48,120\n",
      "            Linear-4                   [-1, 84]          10,164\n",
      "            Linear-5                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import torchsummary\n",
    "net.to('cuda')\n",
    "torchsummary.summary(net,(1,32,32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
