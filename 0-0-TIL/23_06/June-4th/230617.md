# 230617
- 데이콘 월간 데이콘 법원 판결 예측 AI 경진대회 준비
0. 오늘의 의문 
    - 트레이닝과 밸리데이션 데이터에서 예측된 f1스코어는 데이콘 스코어와 서로 비례하지 않은 것 같다. 왜 그럴까?<br><br>
1. 데이콘 스코어 0.5를 넘겨 보기
    -  TF-iDF + LDA + XGboost에서 LDA 제거해보기.
        - TF는 하나의 문서 안에서 빈도수가 높은 단어들에게 가중치를 주지만, 전체 문서에서 많이 나오는 단어는 가중치를 적게 준다.
        - LDA는 전체 문서들에서 뽑아온 토픽들이 단어에 배정이 될 때, 토픽이 없는 단어에 빈도수가 높은 단어의 토픽이 달리기 때문에 TF와 서로 반대되는 개념이 아닐까 추측함.
        - 결과 : LDA를 제거 하니 정확도와 f1score가 증가함. 정확도 2프로 증가, f1 score가 0.03 증가했음. LDA이 없어도 크게 상관이 없다.
        - 피드백 : 하지만 여전히 데이콘 점수 0.5를 넘지 않음. 전처리과정에서 문제가 있지 않을까? 퍼스트파티와 세컨드파티를 포함해서 승패 결과에 반영을 해야하는 지 의문이 듦.
        - tf + lda + xgb<br/>
        <a href="https://imgbb.com/"><img src="https://i.ibb.co/7CYWdgV/image.png" alt="image" border="0"></a>
        - tf + xgb<br/>
        <a href="https://imgbb.com/"><img src="https://i.ibb.co/njKkpMz/lda.png" alt="lda" border="0" width="50%" height="50%"></a >
        - tf + lda + xgb나 tf + xgb는 큰 차이가 없었다. 오히려 제거 했을 때 점수가 올랐다.
        
2. Tf-idf + XGboost
    - 그리드서치의 scale_pos_weight를 0.3 고정을 풀고 다시 돌려봤다 (scoring='f1'). 새로운 파라미터로 xgb를 모델링한 결과, 정확도 11프로 증가하고 f1스코어 역시 0.11 증가함. 하지만 데이콘 스코어는 0.5를 넘지 못함.
    - 새로운 파라미터 scale_pos_weight 0.3 고정을 풀어서 승패소 비율을 깸
        ```pyhton
        default_gs_params = {'learning_rate': 0.3, 'max_depth': 3, 'scale_pos_weight': 1, 'subsample': 0.9}
        ```
        <a href="https://imgbb.com/"><img src="https://i.ibb.co/HVPqGvL/image.png" alt="image" border="0" width="50%" height="50%"></a>

3. LDA 
- TF + LDA
    <a href="https://ibb.co/VT7nfts"><img src="https://i.ibb.co/SBhYFPz/image.png" alt="image" border="0"></a>
    <a href="https://imgbb.com/"><img src="https://i.ibb.co/7CYWdgV/image.png" alt="image" border="0"></a>
- CV + LDA
    <a href="https://ibb.co/3NkD0fK"><img src="https://i.ibb.co/J7CfzxZ/image.png" alt="image" border="0"></a>
    <a href="https://imgbb.com/"><img src="https://i.ibb.co/rsPcYGF/image.png" alt="image" border="0"></a>