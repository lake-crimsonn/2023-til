{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 마스크 유넷 학습시키기\n",
    "![image](https://miro.medium.com/v2/resize:fit:1400/1*qNdglJ1ORP3Gq77MmBLhHQ.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨볼루션 함수\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "# 맥스풀링 함수\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "# 업컨볼루션 함수\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    # 일반적인 컨볼루션의 반대 방향으로 진행 up-conv\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(\n",
    "        inputs)  # 스트라이드가 2라서 크기가 2배로 증가 32->64\n",
    "    x = Concatenate()([x, skip])  # [64x64 512, 64x64 512] -> 64x64 1024\n",
    "    x = conv_block(x, num_filters)  # 64x64, 1024 -> 64x64, 512\n",
    "    return x\n",
    "\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape)  # 512x512 3를 받아서 케라스텐서로 변경해줌\n",
    "\n",
    "    s1, p1 = encoder_block(inputs, 64)  # 512, 256\n",
    "    s2, p2 = encoder_block(p1, 128)  # 256, 128\n",
    "    s3, p3 = encoder_block(p2, 256)  # 128,64\n",
    "    s4, p4 = encoder_block(p3, 512)  # 64, 32\n",
    "\n",
    "    # 플래튼 시키면 위치정보를 잃어버리니까 컨블럭에 입력\n",
    "    b1 = conv_block(p4, 1024)  # 32x32 1024\n",
    "\n",
    "    # 이전형태, 저장해둔 위치정보, 채널수\n",
    "    d1 = decoder_block(b1, s4, 512)  # 64x64 512\n",
    "    d2 = decoder_block(d1, s3, 256)  # 128x128 256\n",
    "    d3 = decoder_block(d2, s2, 128)  # 256x256 128\n",
    "    d4 = decoder_block(d3, s1, 64)  # 512x512 64\n",
    "\n",
    "    # 마지막은 클래스 수, 커널은 1, 멀티클래스니까 softmax\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs)  # 모델 인스턴스 생성\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global image_h\n",
    "global image_w\n",
    "global num_classes\n",
    "global classes\n",
    "global rgb_codes\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"labels\", \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels\", \"*.png\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"labels\", \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image_mask(x, y):\n",
    "   \n",
    "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (image_w, image_h))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    y = cv2.resize(y, (image_w, image_h))\n",
    "    y = y.astype(np.int32) # 마스크는 이미 정규화되어있음\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode() # 바이트에서 스트링으로 디코딩\n",
    "        y = y.decode()\n",
    "        return read_image_mask(x, y)\n",
    "\n",
    "    # 파이썬 함수를 텐서플로우 함수의 연산으로 래핑, 텐서 x, y를 받아서 넘파이 작업하고 텐서로 돌려줌\n",
    "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32]) \n",
    "    mask = tf.one_hot(mask, num_classes)\n",
    "\n",
    "    image.set_shape([image_h, image_w, 3])\n",
    "    mask.set_shape([image_h, image_w, num_classes])\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def tf_dataset(X, Y, batch=8):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.shuffle(buffer_size=5000).map(preprocess) # 첫 5000개부터 가져와서 전처리처리하고 셔플함\n",
    "    ds = ds.batch(batch).prefetch(2) # 데이터 로딩을 줄이기 위해서 배치 2개를 미리 가져옴\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 18168/18168 - Valid: 2000/2000 - Test: 2000/2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 시드\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# 폴더 만들어서 모델 저장\n",
    "create_dir(\"files\")\n",
    "\n",
    "# 파라미터\n",
    "image_h = 512\n",
    "image_w = 512\n",
    "num_classes = 11\n",
    "input_shape = (image_h, image_w, 3)\n",
    "batch_size = 8\n",
    "lr = 1e-4 # 0.0001\n",
    "num_epochs = 100\n",
    "\n",
    "# 경로 지정\n",
    "dataset_path = \"C:\\data\\lapa\\LaPa\"\n",
    "model_path = os.path.join(\"files\", \"model.h5\")\n",
    "csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "# RGB 코드와 그에 맞는 클래스\n",
    "rgb_codes = [\n",
    "    [0, 0, 0], [0, 153, 255], [102, 255, 153], [0, 204, 153],\n",
    "    [255, 255, 102], [255, 255, 204], [255, 153, 0], [255, 102, 255],\n",
    "    [102, 0, 51], [255, 204, 255], [255, 0, 102]\n",
    "]\n",
    "\n",
    "# 11개 클래스\n",
    "classes = [\n",
    "    \"background\", \"skin\", \"left eyebrow\", \"right eyebrow\",\n",
    "    \"left eye\", \"right eye\", \"nose\", \"upper lip\", \"inner mouth\",\n",
    "    \"lower lip\", \"hair\"\n",
    "]\n",
    "\n",
    "# 데이터셋 로딩하기\n",
    "(train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_x)}\")\n",
    "print(\"\")\n",
    "train_ds = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_ds = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 512, 512, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 512, 512, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 512, 512, 64  256        ['conv2d[0][0]']                 \n",
      " alization)                     )                                                                 \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 512, 512, 64  0           ['batch_normalization[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 512, 512, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 512, 512, 64  256        ['conv2d_1[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 512, 512, 64  0           ['batch_normalization_1[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 256, 256, 64  0           ['activation_1[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 256, 256, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 256, 256, 12  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_2[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 256, 256, 12  147584      ['activation_2[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 256, 256, 12  512        ['conv2d_3[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 256, 256, 12  0           ['batch_normalization_3[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 128, 128, 12  0          ['activation_3[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 128, 128, 25  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_4[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 128, 128, 25  590080      ['activation_4[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 25  1024       ['conv2d_5[0][0]']               \n",
      " rmalization)                   6)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 128, 128, 25  0           ['batch_normalization_5[0][0]']  \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 64, 64, 256)  0          ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 64, 64, 512)  1180160     ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 64, 64, 512)  2359808     ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 64, 64, 512)  2048       ['conv2d_7[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 64, 64, 512)  0           ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 32, 32, 512)  0          ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 32, 32, 1024  4719616     ['max_pooling2d_3[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_8[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_8[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 32, 32, 1024  9438208     ['activation_8[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 32, 32, 1024  4096       ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 32, 32, 1024  0           ['batch_normalization_9[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 64, 64, 512)  2097664    ['activation_9[0][0]']           \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 64, 64, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 64, 64, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_10[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 64, 64, 512)  2359808     ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 64, 64, 512)  2048       ['conv2d_11[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64, 64, 512)  0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 128, 128, 25  524544     ['activation_11[0][0]']          \n",
      " spose)                         6)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 128, 128, 51  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                2)                                'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 128, 128, 25  1179904     ['concatenate_1[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 128, 128, 25  1024       ['conv2d_12[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_12[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)             (None, 128, 128, 25  590080      ['activation_12[0][0]']          \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 128, 128, 25  1024       ['conv2d_13[0][0]']              \n",
      " ormalization)                  6)                                                                \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 128, 128, 25  0           ['batch_normalization_13[0][0]'] \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 256, 256, 12  131200     ['activation_13[0][0]']          \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 256, 256, 25  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                6)                                'activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)             (None, 256, 256, 12  295040      ['concatenate_2[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 256, 256, 12  512        ['conv2d_14[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_14[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)             (None, 256, 256, 12  147584      ['activation_14[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 256, 256, 12  512        ['conv2d_15[0][0]']              \n",
      " ormalization)                  8)                                                                \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 256, 256, 12  0           ['batch_normalization_15[0][0]'] \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 512, 512, 64  32832      ['activation_15[0][0]']          \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 512, 512, 12  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                8)                                'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)             (None, 512, 512, 64  73792       ['concatenate_3[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_16 (BatchN  (None, 512, 512, 64  256        ['conv2d_16[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_16[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)             (None, 512, 512, 64  36928       ['activation_16[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_17 (BatchN  (None, 512, 512, 64  256        ['conv2d_17[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 512, 512, 64  0           ['batch_normalization_17[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)             (None, 512, 512, 11  715         ['activation_17[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 31,055,947\n",
      "Trainable params: 31,044,171\n",
      "Non-trainable params: 11,776\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 모델 빌드하기\n",
    "model = build_unet(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    optimizer=tf.keras.optimizers.Adam(lr)\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model/batch_normalization_3/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10188\\629947972.py\", line 8, in <module>\n      model.fit(train_ds,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_3/FusedBatchNormV3'\nOOM when allocating tensor with shape[8,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_3/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5197]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m      2\u001b[0m     ModelCheckpoint(model_path, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m      3\u001b[0m     ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m      4\u001b[0m     CSVLogger(csv_path, append\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m      5\u001b[0m     EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m ]\n\u001b[1;32m----> 8\u001b[0m model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[0;32m      9\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalid_ds,\n\u001b[0;32m     10\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m     11\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model/batch_normalization_3/FusedBatchNormV3' defined at (most recent call last):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_10188\\629947972.py\", line 8, in <module>\n      model.fit(train_ds,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 767, in call\n      outputs = self._fused_batch_norm(inputs, training=training)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 623, in _fused_batch_norm\n      output, mean, variance = control_flow_util.smart_cond(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\control_flow_util.py\", line 105, in smart_cond\n      return tf.__internal__.smart_cond.smart_cond(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py\", line 589, in _fused_batch_norm_training\n      return tf.compat.v1.nn.fused_batch_norm(\nNode: 'model/batch_normalization_3/FusedBatchNormV3'\nOOM when allocating tensor with shape[8,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model/batch_normalization_3/FusedBatchNormV3}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_5197]"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "    CSVLogger(csv_path, append=True),\n",
    "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "]\n",
    "\n",
    "model.fit(train_ds,\n",
    "    validation_data=valid_ds,\n",
    "    epochs=num_epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
