{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os # 출력 경고창 없애기\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" \n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs) \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPool2D((2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip, num_filters):\n",
    "    # 일반적인 컨볼루션의 반대 방향으로 진행 up-conv\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs) # 스트라이드가 2라서 크기가 2배로 증가 32->64\n",
    "    x = Concatenate()([x, skip]) # [64x64 512, 64x64 512] -> 64x64 1024\n",
    "    x = conv_block(x, num_filters) # 64x64, 1024 -> 64x64, 512\n",
    "    return x\n",
    "\n",
    "def build_unet(input_shape, num_classes):\n",
    "    inputs = Input(input_shape) # 512x512 3를 받아서 케라스텐서로 변경해줌\n",
    "    \n",
    "    s1, p1 = encoder_block(inputs, 64) # 512, 256 \n",
    "    s2, p2 = encoder_block(p1, 128) # 256, 128\n",
    "    s3, p3 = encoder_block(p2, 256) # 128,64\n",
    "    s4, p4 = encoder_block(p3, 512) # 64, 32\n",
    "\n",
    "    # 플래튼 시키면 위치정보를 잃어버리니까 컨블럭에 입력\n",
    "    b1 = conv_block(p4, 1024) # 32x32 1024\n",
    "\n",
    "    # 이전형태, 저장해둔 위치정보, 채널수\n",
    "    d1 = decoder_block(b1, s4, 512) # 64x64 512 \n",
    "    d2 = decoder_block(d1, s3, 256) # 128x128 256\n",
    "    d3 = decoder_block(d2, s2, 128) # 256x256 128\n",
    "    d4 = decoder_block(d3, s1, 64) # 512x512 64\n",
    "\n",
    "    # 마지막은 클래스 수, 커널은 1, 멀티클래스니까 softmax\n",
    "    outputs = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(d4)\n",
    "\n",
    "    model = Model(inputs, outputs) # 모델 인스턴스 생성\n",
    "    return model\n",
    "\n",
    "# 인터프리터에서 직접 실행이 되는 경\n",
    "if __name__ == \"__main__\":\n",
    "    input_shape = (512, 512, 3)\n",
    "    model = build_unet(input_shape, 11)\n",
    "    # model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 18168/18168 - Valid: 2000/2000 - Test: 2000/2000\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'model_2/conv2d_41/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6312\\3101084176.py\", line 126, in <module>\n      model.fit(train_ds,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_2/conv2d_41/Conv2D'\nOOM when allocating tensor with shape[8,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/conv2d_41/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7903]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 126\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Training \"\"\"\u001b[39;00m\n\u001b[0;32m    119\u001b[0m     callbacks \u001b[39m=\u001b[39m [\n\u001b[0;32m    120\u001b[0m         ModelCheckpoint(model_path, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, save_best_only\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[0;32m    121\u001b[0m         ReduceLROnPlateau(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, factor\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, min_lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m),\n\u001b[0;32m    122\u001b[0m         CSVLogger(csv_path, append\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m),\n\u001b[0;32m    123\u001b[0m         EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m    124\u001b[0m     ]\n\u001b[1;32m--> 126\u001b[0m     model\u001b[39m.\u001b[39;49mfit(train_ds,\n\u001b[0;32m    127\u001b[0m         validation_data\u001b[39m=\u001b[39;49mvalid_ds,\n\u001b[0;32m    128\u001b[0m         epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m    129\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    130\u001b[0m     )\n\u001b[0;32m    135\u001b[0m \u001b[39m## ..\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'model_2/conv2d_41/Conv2D' defined at (most recent call last):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_6312\\3101084176.py\", line 126, in <module>\n      model.fit(train_ds,\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n      y_pred = self(x, training=True)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 451, in call\n      return self._run_internal_graph(\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\functional.py\", line 589, in _run_internal_graph\n      outputs = node.layer(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\engine\\base_layer.py\", line 1096, in __call__\n      outputs = call_fn(inputs, *args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 92, in error_handler\n      return fn(*args, **kwargs)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 248, in call\n      outputs = self.convolution_op(inputs, self.kernel)\n    File \"c:\\Users\\user\\miniconda3\\envs\\gpu2\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 233, in convolution_op\n      return tf.nn.convolution(\nNode: 'model_2/conv2d_41/Conv2D'\nOOM when allocating tensor with shape[8,128,256,256] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node model_2/conv2d_41/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_7903]"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, CSVLogger\n",
    "from unet import build_unet\n",
    "\n",
    "global image_h\n",
    "global image_w\n",
    "global num_classes\n",
    "global classes\n",
    "global rgb_codes\n",
    "\n",
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def load_dataset(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*.jpg\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"labels\", \"*.png\")))\n",
    "\n",
    "    valid_x = sorted(glob(os.path.join(path, \"val\", \"images\", \"*.jpg\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"val\", \"labels\", \"*.png\")))\n",
    "\n",
    "    test_x = sorted(glob(os.path.join(path, \"test\", \"images\", \"*.jpg\")))\n",
    "    test_y = sorted(glob(os.path.join(path, \"test\", \"labels\", \"*.png\")))\n",
    "\n",
    "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
    "\n",
    "def read_image_mask(x, y):\n",
    "    \"\"\" Image \"\"\"\n",
    "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (image_w, image_h))\n",
    "    x = x/255.0\n",
    "    x = x.astype(np.float32)\n",
    "\n",
    "    \"\"\" Mask \"\"\"\n",
    "    y = cv2.imread(y, cv2.IMREAD_GRAYSCALE)\n",
    "    y = cv2.resize(y, (image_w, image_h))\n",
    "    y = y.astype(np.int32)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def preprocess(x, y):\n",
    "    def f(x, y):\n",
    "        x = x.decode()\n",
    "        y = y.decode()\n",
    "        return read_image_mask(x, y)\n",
    "\n",
    "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n",
    "    mask = tf.one_hot(mask, num_classes)\n",
    "\n",
    "    image.set_shape([image_h, image_w, 3])\n",
    "    mask.set_shape([image_h, image_w, num_classes])\n",
    "\n",
    "    return image, mask\n",
    "\n",
    "def tf_dataset(X, Y, batch=8):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((X, Y))\n",
    "    ds = ds.shuffle(buffer_size=5000).map(preprocess)\n",
    "    ds = ds.batch(batch).prefetch(2)\n",
    "    return ds\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\" Seeding \"\"\"\n",
    "    np.random.seed(42)\n",
    "    tf.random.set_seed(42)\n",
    "\n",
    "    \"\"\" Directory for storing files \"\"\"\n",
    "    create_dir(\"files\")\n",
    "\n",
    "    \"\"\" Hyperparameters \"\"\"\n",
    "    image_h = 512\n",
    "    image_w = 512\n",
    "    num_classes = 11\n",
    "    input_shape = (image_h, image_w, 3)\n",
    "    batch_size = 8\n",
    "    lr = 1e-4 ## 0.0001\n",
    "    num_epochs = 100\n",
    "\n",
    "    \"\"\" Paths \"\"\"\n",
    "    dataset_path = \"C:\\data\\lapa\\LaPa\"\n",
    "    model_path = os.path.join(\"files\", \"model.h5\")\n",
    "    csv_path = os.path.join(\"files\", \"data.csv\")\n",
    "\n",
    "    \"\"\" RGB Code and Classes \"\"\"\n",
    "    rgb_codes = [\n",
    "        [0, 0, 0], [0, 153, 255], [102, 255, 153], [0, 204, 153],\n",
    "        [255, 255, 102], [255, 255, 204], [255, 153, 0], [255, 102, 255],\n",
    "        [102, 0, 51], [255, 204, 255], [255, 0, 102]\n",
    "    ]\n",
    "\n",
    "    classes = [\n",
    "        \"background\", \"skin\", \"left eyebrow\", \"right eyebrow\",\n",
    "        \"left eye\", \"right eye\", \"nose\", \"upper lip\", \"inner mouth\",\n",
    "        \"lower lip\", \"hair\"\n",
    "    ]\n",
    "\n",
    "    \"\"\" Loading the dataset \"\"\"\n",
    "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_dataset(dataset_path)\n",
    "    print(f\"Train: {len(train_x)}/{len(train_y)} - Valid: {len(valid_x)}/{len(valid_y)} - Test: {len(test_x)}/{len(test_x)}\")\n",
    "    print(\"\")\n",
    "\n",
    "    \"\"\" Dataset Pipeline \"\"\"\n",
    "    train_ds = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "    valid_ds = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
    "\n",
    "    \"\"\" Model \"\"\"\n",
    "    model = build_unet(input_shape, num_classes)\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.Adam(lr)\n",
    "    )\n",
    "\n",
    "    \"\"\" Training \"\"\"\n",
    "    callbacks = [\n",
    "        ModelCheckpoint(model_path, verbose=1, save_best_only=True, monitor='val_loss'),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, min_lr=1e-7, verbose=1),\n",
    "        CSVLogger(csv_path, append=True),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]\n",
    "\n",
    "    model.fit(train_ds,\n",
    "        validation_data=valid_ds,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## .."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
