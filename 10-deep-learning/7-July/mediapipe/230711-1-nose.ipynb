{"cells":[{"cell_type":"markdown","id":"7f6063fb","metadata":{"id":"7f6063fb"},"source":["## 1. 코에 동그라미 그리기(1)\n","-- base 에서 작업합니다. 현대 gpu모델에서 모듈 부딪힘."]},{"cell_type":"code","execution_count":3,"id":"7d31e7f7","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting opencv-python\n","  Using cached opencv_python-4.8.0.74-cp37-abi3-win_amd64.whl (38.1 MB)\n","Requirement already satisfied: numpy>=1.19.3 in c:\\users\\user\\miniconda3\\lib\\site-packages (from opencv-python) (1.24.3)\n","Installing collected packages: opencv-python\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: Could not install packages due to an OSError: [WinError 5] 액세스가 거부되었습니다: 'c:\\\\Users\\\\user\\\\miniconda3\\\\Lib\\\\site-packages\\\\cv2\\\\cv2.pyd'\n","Consider using the `--user` option or check the permissions.\n","\n"]},{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: mediapipe in c:\\users\\user\\miniconda3\\lib\\site-packages (0.10.2)\n","Requirement already satisfied: absl-py in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: numpy in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (1.24.3)\n","Requirement already satisfied: protobuf<4,>=3.11 in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (3.20.3)\n","Requirement already satisfied: matplotlib in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (3.7.2)\n","Requirement already satisfied: attrs>=19.1.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (23.1.0)\n","Requirement already satisfied: opencv-contrib-python in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (4.8.0.74)\n","Requirement already satisfied: sounddevice>=0.4.4 in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (0.4.6)\n","Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from mediapipe) (23.5.26)\n","Requirement already satisfied: CFFI>=1.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from sounddevice>=0.4.4->mediapipe) (1.15.1)\n","Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.1.0)\n","Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (4.40.0)\n","Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (23.0)\n","Requirement already satisfied: pillow>=6.2.0 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (10.0.0)\n","Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (3.0.9)\n","Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (1.4.4)\n","Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\miniconda3\\lib\\site-packages (from matplotlib->mediapipe) (0.11.0)\n","Requirement already satisfied: pycparser in c:\\users\\user\\miniconda3\\lib\\site-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.21)\n","Requirement already satisfied: six>=1.5 in c:\\users\\user\\miniconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.16.0)\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["%pip install opencv-python\n","%pip install mediapipe"]},{"cell_type":"code","execution_count":4,"id":"1f49ee40","metadata":{"id":"1f49ee40"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","\n","\n","\n","# 얼굴 찾고, 특징 표시\n","mp_face_detection = mp.solutions.face_detection #얼굴 검출\n","mp_drawing = mp.solutions.drawing_utils # 얼굴 특징 표시\n","\n","# For webcam input:\n","cap = cv2.VideoCapture(0)\n","# model_selection=0 -> 2m 내, model_selection=1 -> 5m 내\n","with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n","      while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Ignoring empty camera frame.\")\n","            # If loading a video, use 'break' instead of 'continue'.\n","            break\n","\n","        # To improve performance, optionally mark the image as not writeable to\n","        # pass by reference.\n","        image.flags.writeable = False\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = face_detection.process(image)\n","\n","        # Draw the face detection annotations on the image.\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        if results.detections:\n","            for detection in results.detections:\n","                mp_drawing.draw_detection(image, detection) # detection 한 모든 부분 표시\n","               \n","                #코 좌표 잡기\n","                nose_coor = detection.location_data.relative_keypoints[2]\n","\n","                #코의 상대좌표를 이미지 내 좌표로 변환\n","                h,w,_ = image.shape\n","                nose_coor = (int(nose_coor.x * w) , int(nose_coor.y * h))\n","\n","                #코에 동그라미 그리기\n","                cv2.circle(image,nose_coor,20,(255,0,0),2,cv2.LINE_AA)\n","\n","                \n","        # Flip the image horizontally for a selfie-view display.\n","        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n","        if cv2.waitKey(5) & 0xFF == ord('q'):\n","            break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"9a8e4974","metadata":{"id":"9a8e4974"},"source":["## 2. 코에 동그라미 그리기(2) \n","- 얼굴 너비에 비례한 코 동그라미 적용"]},{"cell_type":"code","execution_count":5,"id":"67a25777","metadata":{"id":"67a25777"},"outputs":[],"source":["import cv2\n","import mediapipe as mp\n","\n","\n","\n","# 얼굴 찾고, 특징 표시\n","mp_face_detection = mp.solutions.face_detection #얼굴 검출\n","mp_drawing = mp.solutions.drawing_utils # 얼굴 특징 표시\n","\n","# For webcam input:\n","cap = cv2.VideoCapture(0)\n","# model_selection=0 -> 2m 내, model_selection=1 -> 5m 내\n","with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n","      while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Ignoring empty camera frame.\")\n","            # If loading a video, use 'break' instead of 'continue'.\n","            break\n","\n","        # To improve performance, optionally mark the image as not writeable to\n","        # pass by reference.\n","        image.flags.writeable = False\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = face_detection.process(image)\n","\n","        # Draw the face detection annotations on the image.\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        if results.detections:\n","            for detection in results.detections:\n","                mp_drawing.draw_detection(image, detection) # detection 한 모든 부분 표시\n","               \n","                #코 좌표 잡기\n","                nose_coor = detection.location_data.relative_keypoints[2]\n","                ratio = int(80*detection.location_data.relative_bounding_box.width) #얼굴너비를 기준으로 ratio 계산\n","                #print(detection.location_data.relative_bounding_box.width,ratio)\n","\n","                #코의 상대좌표를 이미지 내 좌표로 변환\n","                h,w,_ = image.shape\n","                nose_coor = (int(nose_coor.x * w) , int(nose_coor.y * h))\n","\n","                #코에 동그라미 그리기\n","                cv2.circle(image,nose_coor,ratio,(255,0,0),2,cv2.LINE_AA)\n","\n","                \n","        # Flip the image horizontally for a selfie-view display.\n","        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n","        if cv2.waitKey(5) & 0xFF == ord('q'):\n","            break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"f28b387a","metadata":{"id":"f28b387a"},"source":["## 3. 코에 돼지코 합성"]},{"cell_type":"code","execution_count":6,"id":"0cf07e72","metadata":{"id":"0cf07e72"},"outputs":[{"ename":"ValueError","evalue":"not enough values to unpack (expected 3, got 0)","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[6], line 63\u001b[0m\n\u001b[0;32m     60\u001b[0m left_ear \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m(left_ear\u001b[39m.\u001b[39mx \u001b[39m*\u001b[39m w) , \u001b[39mint\u001b[39m(left_ear\u001b[39m.\u001b[39my \u001b[39m*\u001b[39m h\u001b[39m-\u001b[39m\u001b[39m80\u001b[39m))\n\u001b[0;32m     62\u001b[0m \u001b[39m#코에 이미지 합성 () overlay(원본이미지, x,y, 합성할 png이미지)  => x,y :합성할 이미지 픽셀 위치\u001b[39;00m\n\u001b[1;32m---> 63\u001b[0m overlay(image, nose_coor[\u001b[39m0\u001b[39;49m], nose_coor[\u001b[39m1\u001b[39;49m], nose_img)\n\u001b[0;32m     64\u001b[0m overlay(image, right_ear[\u001b[39m0\u001b[39m], right_ear[\u001b[39m1\u001b[39m], right_img)\n\u001b[0;32m     65\u001b[0m overlay(image, left_ear[\u001b[39m0\u001b[39m], left_ear[\u001b[39m1\u001b[39m], left_img)\n","Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36moverlay\u001b[1;34m(image, x, y, over_image)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moverlay\u001b[39m(image, x, y,over_image):\n\u001b[0;32m      7\u001b[0m     tmp\u001b[39m=\u001b[39mover_image\n\u001b[1;32m----> 8\u001b[0m     over_h, over_w, _ \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mshape(tmp)\n\u001b[0;32m     10\u001b[0m     w\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(over_w\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     11\u001b[0m     h\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m(over_h\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m)\n","\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"]}],"source":["import cv2\n","import mediapipe as mp\n","import numpy as np\n","\n","#이미지 합성 (원본이미지, 원본x좌표, 원본y 좌표, 합성할 png(4채널)이미지)\n","def overlay(image, x, y,over_image):\n","    tmp=over_image\n","    over_h, over_w, _ = np.shape(tmp)\n","\n","    w=int(over_w/2)\n","    h=int(over_h/2)\n","    mask_img=tmp[:,:,3]/255\n","    try:\n","        for c in range(3):\n","            image[y-h:y+h,x-w:x+w,c]=((tmp[:,:,c]*mask_img)+(image[y-h:y+h,x-w:x+w,c]*(1-mask_img)))#.astype(np.uint8)\n","    except:\n","        pass\n","\n","nose_img=cv2.imread('./nose150.png',cv2.IMREAD_UNCHANGED) # 150x500\n","left_img=cv2.imread('./left_ear80.png',cv2.IMREAD_UNCHANGED) # 300x100\n","right_img=cv2.imread('./right_ear80.png',cv2.IMREAD_UNCHANGED) # 300x100\n","\n","# 얼굴 찾고, 특징 표시\n","mp_face_detection = mp.solutions.face_detection #얼굴 검출\n","mp_drawing = mp.solutions.drawing_utils # 얼굴 특징 표시\n","\n","# For webcam input:\n","cap = cv2.VideoCapture(0)\n","# model_selection=0 -> 2m 내, model_selection=1 -> 5m 내\n","with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n","      while cap.isOpened():\n","        success, image = cap.read()\n","        if not success:\n","            print(\"Ignoring empty camera frame.\")\n","            # If loading a video, use 'break' instead of 'continue'.\n","            break\n","\n","        # To improve performance, optionally mark the image as not writeable to\n","        # pass by reference.\n","        image.flags.writeable = False\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        results = face_detection.process(image)\n","\n","        # Draw the face detection annotations on the image.\n","        image.flags.writeable = True\n","        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n","        if results.detections:\n","            for detection in results.detections:\n","                #mp_drawing.draw_detection(image, detection) # detection 한 모든 부분 표시\n","               \n","                #코,오른쩍 귀, 왼쪽 귀 좌표 잡기 \n","                nose_coor = detection.location_data.relative_keypoints[2] # 코\n","                right_ear = detection.location_data.relative_keypoints[4] # 오른쪽 귀\n","                left_ear = detection.location_data.relative_keypoints[5]  #왼쪽 귀\n","\n","                #코,오른쩍 귀, 왼쪽 귀의 이미지 내 실제 좌표(픽셀)\n","                h,w,_ = image.shape\n","                nose_coor = (int(nose_coor.x * w) , int(nose_coor.y * h))\n","                right_ear = (int(right_ear.x * w) , int(right_ear.y * h-80))\n","                left_ear = (int(left_ear.x * w) , int(left_ear.y * h-80))\n","             \n","                #코에 이미지 합성 () overlay(원본이미지, x,y, 합성할 png이미지)  => x,y :합성할 이미지 픽셀 위치\n","                overlay(image, nose_coor[0], nose_coor[1], nose_img)\n","                overlay(image, right_ear[0], right_ear[1], right_img)\n","                overlay(image, left_ear[0], left_ear[1], left_img)\n","\n","                \n","        # Flip the image horizontally for a selfie-view display.\n","        cv2.imshow('MediaPipe Face Detection', cv2.flip(image, 1))\n","        if cv2.waitKey(5) & 0xFF == ord('q'):\n","            break\n","cap.release()\n","cv2.destroyAllWindows()"]},{"cell_type":"markdown","id":"177fc479","metadata":{"id":"177fc479"},"source":["# "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":5}
